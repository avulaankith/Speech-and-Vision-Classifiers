# -*- coding: utf-8 -*-
"""caltechchallenge.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LIv6nvwt1rXLmkwoa3BO8VDKUKnGxU7C
"""

from google.colab import drive
drive.mount('/content/drive/')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch

!pip install timm pandas requests

import os
ds_path = "/content/drive/MyDrive/datasets/Caltech Challenge/256_ObjectCategories/"

print(sorted(os.listdir(ds_path)))
print(len(sorted(os.listdir(ds_path))))

# from PIL import Image
# import cv2
# for folder in os.listdir(ds_path):
#   print(folder)
#   print(len(os.listdir(f"{ds_path}/{folder}")))
#   # for img in os.listdir(f"{ds_path}/{folder}")[:5]:
#   #   print(img)
#   #   imgpil = Image.open(f"{ds_path}/{folder}/{img}")
#   #   imgpil = imgpil.resize((224, 224))
#   #   print(imgpil.width,imgpil.height)
#   #   npimg = np.array(imgpil)
#   #   plt.imshow(npimg)
#   #   plt.show()
#   print("---------------------------")

import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, WeightedRandomSampler
import numpy as np

# Define data augmentation transforms for training data
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224),     # Random crop and resize
    transforms.RandomHorizontalFlip(),     # Random horizontal flip
    transforms.ColorJitter(),              # Random color jitter
    transforms.RandomRotation(10),         # Random rotation
    transforms.ToTensor(),                 # Convert images to PyTorch tensors
    transforms.Normalize(                  # Normalize image tensors
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# Define transforms for validation data (without augmentation)
val_transform = transforms.Compose([
    transforms.Resize((224, 224)),        # Resize images to 229x229
    transforms.ToTensor(),                 # Convert images to PyTorch tensors
    transforms.Normalize(                  # Normalize image tensors
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# Load the dataset
dataset = datasets.ImageFolder(root=ds_path)

# Calculate the sizes for train and validation datasets
total_data = len(dataset)
train_size = int(0.9 * total_data)
val_size = total_data - train_size

# Split the dataset into train and val
train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])

# Apply transforms to train and val datasets
train_dataset.dataset.transform = train_transform
val_dataset.dataset.transform = val_transform

# Calculate class weights for WeightedRandomSampler
class_counts = np.bincount(train_dataset.dataset.targets)
class_weights = 1 / torch.tensor(class_counts, dtype=torch.float)

# Create a sampler to balance classes in the training set
train_sampler = WeightedRandomSampler(weights=class_weights, num_samples=train_size)

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=32, sampler=train_sampler)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

import torchvision

# Get the class names from the dataset
class_names = train_dataset.dataset.classes

# Define a function to display images from a batch with original label names
def show_images_with_labels(images, labels, class_names):
    # Make a grid from batch
    grid = torchvision.utils.make_grid(images, nrow=8)
    plt.imshow(np.transpose(grid, (1, 2, 0)))
    plt.title('Batch from DataLoader')
    plt.axis('off')
    plt.show()
    print('Labels (Numerical):', labels)
    print('Labels (Original):', [class_names[label] for label in labels])

# Iterate over batches in train_loader and val_loader
for batch_idx, (images, labels) in enumerate(train_loader):
    print(f'Batch {batch_idx + 1} (Training)')
    show_images_with_labels(images, labels, class_names)
    break  # Break after printing the first batch for demonstration

for batch_idx, (images, labels) in enumerate(val_loader):
    print(f'Batch {batch_idx + 1} (Validation)')
    show_images_with_labels(images, labels, class_names)
    break  # Break after printing the first batch for demonstration

len(train_dataset.dataset.classes)

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import torch.backends.cudnn as cudnn
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
from PIL import Image
from tempfile import TemporaryDirectory

cudnn.benchmark = True
plt.ion()   # interactive mode

def imshow(inp, title=None):
    """Display image for Tensor."""
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.pause(0.001)  # pause a bit so that plots are updated


# Get a batch of training data
inputs, classes = next(iter(train_loader))

# Make a grid from batch
out = torchvision.utils.make_grid(inputs)

imshow(out, title=[class_names[x] for x in classes])

len(train_dataset)

len(val_dataset)



device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

def train_model(model, criterion, optimizer, scheduler, num_epochs=5):
    since = time.time()

    # Create a temporary directory to save training checkpoints
    with TemporaryDirectory() as tempdir:
        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')

        torch.save(model.state_dict(), best_model_params_path)
        best_acc = 0.0

        for epoch in range(num_epochs):
            print(f'Epoch {epoch}/{num_epochs - 1}')
            print('-' * 10)

            # Each epoch has a training and validation phase
            for phase in ['train', 'val']:
                if phase == 'train':
                    dataloader = train_loader
                    model.train()  # Set model to training mode
                else:
                    dataloader = val_loader
                    model.eval()   # Set model to evaluate mode

                running_loss = 0.0
                running_corrects = 0

                # Iterate over data.
                for inputs, labels in dataloader:
                    inputs = inputs.to(device)
                    labels = labels.to(device)

                    # zero the parameter gradients
                    optimizer.zero_grad()

                    # forward
                    # track history if only in train
                    with torch.set_grad_enabled(phase == 'train'):
                        outputs = model(inputs)
                        _, preds = torch.max(outputs, 1)
                        loss = criterion(outputs, labels)

                        # backward + optimize only if in training phase
                        if phase == 'train':
                            loss.backward()
                            optimizer.step()

                    # statistics
                    running_loss += loss.item() * inputs.size(0)
                    running_corrects += torch.sum(preds == labels.data)
                if phase == 'train':
                    scheduler.step()

                if phase == "train":
                  dataset_size = len(train_dataset)
                else:
                  dataset_size = len(val_dataset)
                epoch_loss = running_loss / dataset_size
                epoch_acc = running_corrects.double() / dataset_size

                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

                # deep copy the model
                if phase == 'val' and epoch_acc > best_acc:
                    best_acc = epoch_acc
                    torch.save(model.state_dict(), best_model_params_path)

            print()

        time_elapsed = time.time() - since
        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
        print(f'Best val Acc: {best_acc:4f}')

        # load best model weights
        model.load_state_dict(torch.load(best_model_params_path))
    return model



# Import necessary libraries
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torchvision import models
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch.utils.data import DataLoader

# Define additional layers with dropout and regularization
class AdditionalLayers(nn.Module):
    def __init__(self, in_features, num_classes):
        super(AdditionalLayers, self).__init__()
        self.fc1 = nn.Linear(in_features, 512)
        self.dropout1 = nn.Dropout(0.5)  # Dropout layer after first fully connected layer
        self.fc2 = nn.Linear(512, 256)
        self.dropout2 = nn.Dropout(0.5)  # Dropout layer after second fully connected layer
        self.fc3 = nn.Linear(256, num_classes)
        self.dropout3 = nn.Dropout(0.5)  # Dropout layer after third fully connected layer

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.dropout1(x)
        x = F.relu(self.fc2(x))
        x = self.dropout2(x)
        x = self.fc3(x)
        return x

num_classes = 257
batch_size = 32

# Load pre-trained ResNet101 model
model_conv = models.resnet101(pretrained=True)

# Freeze all layers except the final classification layer
for param in model_conv.parameters():
    param.requires_grad = False

# Replace the final classification layer with additional layers
num_ftrs = model_conv.fc.in_features
model_conv.fc = AdditionalLayers(num_ftrs, num_classes)

# Define device (GPU if available, else CPU)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model_conv = model_conv.to(device)

# # Define dataloaders for training and validation
# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

# Define loss function
criterion = nn.CrossEntropyLoss()

# Use Adam optimizer
optimizer_conv = optim.Adam(model_conv.parameters(), lr=0.001)

# Define learning rate scheduler
scheduler = exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)

# Train the model
model_conv = train_model(model_conv, criterion, optimizer_conv, scheduler, num_epochs=5)

# Save the trained model
torch.save(model_conv.state_dict(), 'best_model.pt')


# model_conv = torchvision.models.resnet50(weights='IMAGENET1K_V2')
# # model_conv = models.inception_v3(pretrained=True)
# # for param in model_conv.parameters():
# #     param.requires_grad = False

# # Parameters of newly constructed modules have requires_grad=True by default
# num_ftrs = model_conv.fc.in_features
# model_conv.fc = nn.Linear(num_ftrs, 257)

# # num_ftrs = model_conv.AuxLogits.fc.in_features
# # model_conv.AuxLogits.fc = nn.Linear(num_ftrs, 2)
# # # Handle the primary net
# # num_ftrs = model_conv.fc.in_features
# # model_conv.fc = nn.Linear(num_ftrs, 2)


# model_conv = model_conv.to(device)

# criterion = nn.CrossEntropyLoss()

# # Observe that only parameters of final layer are being optimized as
# # opposed to before.
# optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)

# # Decay LR by a factor of 0.1 every 7 epochs
# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)

# model_conv = train_model(model_conv, criterion, optimizer_conv,
#                          exp_lr_scheduler, num_epochs=5)

# Train the model
model_conv = train_model(model_conv, criterion, optimizer_conv, scheduler, num_epochs=15)

# Save the trained model
torch.save(model_conv.state_dict(), 'best_model.pt')

def visualize_model(model, num_images=6):
    was_training = model.training
    model.eval()
    images_so_far = 0
    fig = plt.figure()

    with torch.no_grad():
        for i, (inputs, labels) in enumerate(val_loader):
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            for j in range(inputs.size()[0]):
                images_so_far += 1
                ax = plt.subplot(num_images//2, 2, images_so_far)
                ax.axis('off')
                ax.set_title(f'predicted: {class_names[preds[j]]}')
                imshow(inputs.cpu().data[j])

                if images_so_far == num_images:
                    model.train(mode=was_training)
                    return
        model.train(mode=was_training)

visualize_model(model_conv)

"""Other approches considered are visual transformers."""

